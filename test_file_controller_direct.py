#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥ä½¿ç”¨FileControlleræµ‹è¯•å¤§æ–‡ä»¶å‘¨æœŸGLINKçš„XMLå±•å¼€
"""

import os
import sys
import json
import xml.etree.ElementTree as ET

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath('.'))

# å°è¯•åœ¨ä¸åˆ›å»ºQApplicationçš„æƒ…å†µä¸‹æµ‹è¯•
def test_file_controller_without_qt():
    """
    ç›´æ¥å¯¼å…¥FileControllerçš„å…³é”®éƒ¨åˆ†å¹¶æµ‹è¯•
    """
    print("ç›´æ¥æµ‹è¯•FileControllerçš„å¤§æ–‡ä»¶XMLå±•å¼€é€»è¾‘...")
    
    # å¯¼å…¥æ‰€éœ€çš„æ¨¡å—
    import uuid
    from controllers.file_controller import FileController
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„å¤§æ–‡ä»¶
    test_file_path = "test_large_file.txt"
    num_rows = 50  # æµ‹è¯•ç”¨çš„è¡Œæ•°
    num_cols = 16
    
    with open(test_file_path, 'w') as f:
        for i in range(num_rows):
            line = ' '.join(['1' for _ in range(num_cols)]) + '\n'
            f.write(line)
    
    print(f"åˆ›å»ºæµ‹è¯•æ–‡ä»¶ {test_file_path}ï¼ŒåŒ…å« {num_rows} è¡Œï¼Œæ¯è¡Œ {num_cols} åˆ—")
    
    try:
        # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ­¥éª¤æ•°æ®
        step_data = {
            "base": {
                "step_id": f"test_step_{uuid.uuid4().hex[:8]}",
                "step_name": "æµ‹è¯•å¤§æ–‡ä»¶å‘¨æœŸGLINK",
                "step_type": 1,  # GLINKå‘¨æœŸç±»å‹
                "time": 100.0
            },
            "type": {
                "file_path": test_file_path,
                "period": 10.0,
                "start_time": 0
            },
            "expand": {
                "periodic_file_path": test_file_path
            },
            "protocol": {
                "protocol_type": -1
            }
        }
        
        # æ¨¡æ‹ŸFileControllerä¸­çš„å¤§æ–‡ä»¶å¤„ç†é€»è¾‘
        print("æ¨¡æ‹ŸFileControllerçš„å¤§æ–‡ä»¶å¤„ç†é€»è¾‘...")
        
        # æ¨¡æ‹Ÿprocess_large_periodic_fileå‡½æ•°
        def mock_process_large_periodic_file(file_path, data_types):
            processed_data = []
            
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_idx, line in enumerate(f):
                    line = line.strip()
                    if not line:
                        continue
                    
                    values = line.split()
                    if not values:
                        continue
                    
                    # å¦‚æœdata_typesä¸ºç©ºï¼Œè‡ªåŠ¨æ£€æµ‹
                    if not data_types:
                        data_types = [1] * len(values)
                    
                    # ç¡®ä¿æ•°æ®ç±»å‹æ•°é‡ä¸åˆ—æ•°åŒ¹é…
                    if len(data_types) < len(values):
                        data_types.extend([1] * (len(values) - len(data_types)))
                    elif len(data_types) > len(values):
                        data_types = data_types[:len(values)]
                    
                    row_data = []
                    for col_idx, (value, data_type) in enumerate(zip(values, data_types)):
                        row_data.append({
                            "data_type": data_type,
                            "value": value
                        })
                    
                    processed_data.append(row_data)
            
            return processed_data
        
        # è·å–æ•°æ®ç±»å‹
        type_data = step_data["type"]
        data_types = []
        for i in range(1, 13):  # æ£€æŸ¥data_type_1åˆ°data_type_12
            key = f"data_type_{i}"
            if key in type_data and type_data[key] is not None:
                data_types.append(type_data[key])
        
        # å¦‚æœdata_typesä¸ºç©ºï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹
        if not data_types:
            print("æœªæ‰¾åˆ°æ•°æ®ç±»å‹é…ç½®ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼...")
            try:
                with open(test_file_path, 'r', encoding='utf-8') as f:
                    first_line = f.readline().strip()
                    if first_line:
                        values = first_line.split()
                        if values:
                            num_cols = len(values)
                            data_types = [1] * num_cols
                            print(f"æ£€æµ‹åˆ°æ–‡ä»¶æœ‰ {num_cols} åˆ—æ•°æ®")
                    else:
                        # æ–‡ä»¶ä¸ºç©ºï¼Œé»˜è®¤1ä¸ªé€šé“
                        data_types = [1]
                        print("æ–‡ä»¶ä¸ºç©ºï¼Œé»˜è®¤1ä¸ªé€šé“")
            except Exception as e:
                print(f"è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼å¤±è´¥: {str(e)}")
                data_types = [1]
        
        # å¤„ç†å¤§æ–‡ä»¶
        processed_data = mock_process_large_periodic_file(test_file_path, data_types)
        print(f"å¤§æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå…± {len(processed_data)} è¡Œ")
        
        # æ¨¡æ‹ŸXMLå±•å¼€
        print("æ¨¡æ‹ŸXMLå±•å¼€...")
        
        # åˆ›å»ºXMLæ ¹èŠ‚ç‚¹
        root = ET.Element("root")
        steps_elem = ET.SubElement(root, "steps")
        
        base_data = step_data["base"]
        type_data = step_data["type"]
        expand_data = step_data["expand"]
        protocol_data = step_data["protocol"]
        
        file_path_value = type_data.get("file_path") or expand_data.get("periodic_file_path")
        period_value = type_data.get("period")
        
        # ç”Ÿæˆgroup_id
        group_id = f"periodic_{uuid.uuid4().hex}"
        
        # ç¬¬ä¸€è¡Œçš„timeæ¥è‡ªbase_step_dataä¸­çš„time
        first_time = float(base_data.get("time", 0.0))
        period = float(period_value if period_value not in (None, "") else 0.0)
        
        # é™åˆ¶å±•å¼€çš„è¡Œæ•°
        max_rows = min(1000, len(processed_data))
        
        # å±•å¼€æ­¥éª¤
        generated_steps = 0
        for row_idx, row_data in enumerate(processed_data[:max_rows]):
            step_elem = ET.SubElement(steps_elem, "step")
            
            # ä¿å­˜baseå­—å…¸
            base_elem = ET.SubElement(step_elem, "base")
            base_data_copy = base_data.copy()
            base_data_copy["time"] = first_time + row_idx * period
            for k, v in base_data_copy.items():
                field = ET.SubElement(base_elem, k)
                field.text = str(v)
            
            # ä¿å­˜typeå­—å…¸
            type_elem = ET.SubElement(step_elem, "type")
            type_data_copy = {}
            for k, v in type_data.items():
                if k in ("start_time",):
                    continue
                type_data_copy[k] = v
            if file_path_value is not None:
                type_data_copy["file_path"] = file_path_value
            if period_value is not None:
                type_data_copy["period"] = period_value
            
            # è®¾ç½®data_regionä¸ºå½“å‰è¡Œçš„æ•°æ®
            type_data_copy["data_region"] = row_data
            
            for k, v in type_data_copy.items():
                field = ET.SubElement(type_elem, k)
                if k == "data_region":
                    if isinstance(v, (list, dict)):
                        if v:
                            field.text = json.dumps(v, ensure_ascii=False)
                        else:
                            field.text = "[]"
                    elif v is None:
                        field.text = "None"
                    else:
                        field.text = str(v)
                else:
                    field.text = str(v)
            
            # ä¿å­˜expandå­—å…¸
            expand_elem = ET.SubElement(step_elem, "expand")
            for k, v in expand_data.items():
                if k in ("periodic_file_data", "periodic_file_path"):
                    continue
                field = ET.SubElement(expand_elem, k)
                field.text = str(v)
            field = ET.SubElement(expand_elem, "periodic_group_id")
            field.text = group_id
            field = ET.SubElement(expand_elem, "periodic_group_index")
            field.text = str(row_idx)
            field = ET.SubElement(expand_elem, "periodic_group_first")
            field.text = "1" if row_idx == 0 else "0"
            if file_path_value:
                field = ET.SubElement(expand_elem, "periodic_file_path")
                field.text = str(file_path_value)
            
            # ä¿å­˜protocol_dataå­—å…¸
            protocol_elem = ET.SubElement(step_elem, "protocol")
            protocol_type = protocol_data.get("protocol_type", -1)
            if protocol_type != -1:
                for k, v in protocol_data.items():
                    field = ET.SubElement(protocol_elem, k)
                    field.text = str(v)
            
            generated_steps += 1
            
        print(f"æ­¥éª¤å±•å¼€å®Œæˆï¼Œå…±ç”Ÿæˆ {generated_steps} ä¸ªstep")
        
        # éªŒè¯ç»“æœ
        print("\nâœ… éªŒè¯ç»“æœï¼š")
        print(f"   é¢„æœŸç”Ÿæˆçš„stepæ•°é‡: {min(1000, num_rows)}")
        print(f"   å®é™…ç”Ÿæˆçš„stepæ•°é‡: {generated_steps}")
        
        if generated_steps > 1:
            print(f"   ğŸ‰ æµ‹è¯•é€šè¿‡ï¼XMLæ­£ç¡®å±•å¼€äº† {generated_steps} ä¸ªstep")
            return True
        else:
            print(f"   âŒ æµ‹è¯•å¤±è´¥ï¼XMLåªå±•å¼€äº† {generated_steps} ä¸ªstep")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_file_path):
            os.remove(test_file_path)
        if os.path.exists("test_large_file_expansion.xml"):
            os.remove("test_large_file_expansion.xml")


if __name__ == "__main__":
    success = test_file_controller_without_qt()
    if success:
        print("\nğŸ‰ æµ‹è¯•é€šè¿‡ï¼FileControllerçš„å¤§æ–‡ä»¶XMLå±•å¼€é€»è¾‘æ­£å¸¸")
        sys.exit(0)
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼FileControllerçš„å¤§æ–‡ä»¶XMLå±•å¼€é€»è¾‘å­˜åœ¨é—®é¢˜")
        sys.exit(1)